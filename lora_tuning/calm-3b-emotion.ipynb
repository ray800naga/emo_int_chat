{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "from auto_gptq import exllama_set_max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    model_name=\"TheBloke/Swallow-13B-GPTQ\",\n",
    "    learning_rate=1.41e-5,\n",
    "    # log_with=\"wandb\",\n",
    "\t# batch_size=64,\n",
    "\t# mini_batch_size=64\n",
    ")\n",
    "\n",
    "# emotion pipe用の設定\n",
    "sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(config, dataset_name=\"shunk031/wrime\", ver=\"ver1\", input_min_text_length=0, input_max_text_length=8):\n",
    "\ttokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "\t# tokenizer.pad_token = tokenizer.pad_token\n",
    "\ttokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\tds = load_dataset(dataset_name, ver, split=\"train\")\n",
    "\tds = ds.remove_columns([\"user_id\", \"datetime\", \"writer\", \"reader1\", \"reader2\", \"reader3\", \"avg_readers\"])\n",
    "\n",
    "\tdef tokenize(sample):\n",
    "\t\tstc_length = len(tokenizer.encode(sample[\"sentence\"]))\n",
    "\t\tif stc_length < input_max_text_length:\n",
    "\t\t\tinput_size = stc_length\n",
    "\t\telse :\n",
    "\t\t\tinput_size = input_max_text_length\n",
    "\t\tsample[\"input_ids\"] = tokenizer.encode(sample[\"sentence\"])[: input_size]\n",
    "\t\tsample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "\t\treturn sample\n",
    "\n",
    "\tds = ds.map(tokenize, batched=False)\n",
    "\tds.set_format(type=\"torch\")\n",
    "\treturn ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/trl/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for shunk031/wrime contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/shunk031/wrime\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = build_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['ぼけっとしてたらこんな時間｡チャリあるから食べにでたいのに…',\n",
       "  '今日の月も白くて明るい。昨日より雲が少なくてキレイな? と立ち止まる帰り道｡チャリなし生活も悪くない｡',\n",
       "  '早寝するつもりが飲み物がなくなりコンビニへ｡ん､今日、風が涼しいな。',\n",
       "  '眠い、眠れない。',\n",
       "  'ただいま? って新体操してるやん!外食する気満々で家に何もないのに!テレビから離れられない…!',\n",
       "  '表情筋が衰えてきてる｡まずいな…',\n",
       "  'やばい｡おもろいな?思ってみてみた「シャレードがいっぱい」｡よすぎるやん。',\n",
       "  'おなかすいた…夜ご飯仲間募集｡',\n",
       "  'よく寝た。暴走バスの夢見た。からだいたい。',\n",
       "  '最近アップにしていたので気づかなかったけど、ちゃんとブローしたらモテキ小宮山夏樹(後期)に似てきてる｡この感じ定着したらパーマしよ。',\n",
       "  '月末ミーティング終了｡いつものことだが自分のミーティング力のなさに凹む。もう走り出すしかない。バッティングセンターいこうぜ!',\n",
       "  'COWCOWヨシ君の顔色が最近ずっと悪い。病気ちゃうん?心配やわ。',\n",
       "  'シャンプーいきたい…',\n",
       "  'BIGBANGの人がえみちゃんねるにでてた。今、水泳の立石が…似すぎ｡どちらも、生半可に喋りが達者でちょっとウザイ。でも立石なんかすき。',\n",
       "  '久々に自炊した。最近すごくやせたと評判なので、ごはんがすすむおかずをたんと。二膳半たべた。よしっ!',\n",
       "  '雨…（笑）',\n",
       "  '外反母趾が悪化。なぜ?ヒール止めてるし幅広い靴しか履いてないのに｡本格的に治療すっかな｡',\n",
       "  '待ち人は来ないのではないかという疑念がふとよぎる｡涼しくなったなぁ｡',\n",
       "  '昔夢を語った仲間と数年ぶりの再会!相変わらず､だったけど少し大人になっていた僕ら､だった｡それぞれの道で頑張っててきっと色々あるけど、昔みたいに笑える時間が嬉しかった。昔見た未来まであと4年。がんばろ。',\n",
       "  'みんな幸せになったらいいなって、なんか普通にそう思う。日曜と月曜と火曜会った人たちありがとう。また明日からがんばろう｡オヤスミナサイ',\n",
       "  '回鍋肉を作るつもりで何か違うやつになった｡でもウマい!ウマすぎるぜ回鍋肉じゃないやつ!!',\n",
       "  '朝はパンケーキとサンドイッチ､昼はお弁当とサンドイッチ､夜は回鍋肉とごはんとパンケーキ｡昨日焼いたチョコｹｰｷがもう残り30度…好きなものを好きなときにたべるんだ!明日も焼こ。',\n",
       "  '天地明察みたいな?おもろいんかな?',\n",
       "  '不確かな夜風が待ち人連れ去りぬ。???ふと､待ち人は来ないのではないかという疑念に駆られる。微かに絡みつく風に、煮え切らない自分の心を見たようで。…うーむ。いいねぇ｡',\n",
       "  '投げかけたものは返ってくるので､なるべく良いものを投げていたいと思う｡しかし時には叶わないことがある｡そういったとき、自分は試されていると感じる｡そしてたいていの場合､私はその試練に敗ける｡',\n",
       "  '肉まん、サーモンロール、茶碗蒸し、納豆、シナモンロール｡暇やからって食べ過ぎた…(●´з｀●)',\n",
       "  '次の月曜の19時から落語観たい人???',\n",
       "  'ヤバい!2700のBO0WY!!',\n",
       "  '最強の二人、夢売る二人、愛と誠｡観たい映画、メモ…',\n",
       "  'ごくありきたりで俗っぽくて申し訳ないのですが、ミランダ･カーめっちゃ可愛い!めっちゃ好き!いつまでも見てられる…お子様もまたデカくて可愛いんだ!',\n",
       "  '腰をイワしています｡痛み止め飲んでるからか四六時中眠い。いける日は整骨院でほぐしてもらうけど、今日明日休みやん｡テーピングもかゆくなってはがしたし、明日は文字通り丸腰｡夜までもってくれ､腰!',\n",
       "  '落語…どしよかな…それか映画いこかな。',\n",
       "  '結局映画にも落語にも整体にも行けず、せめて夕飯はと思ったのに怠けグセがついて､出前とってしまった｡全力で安静中♪',\n",
       "  '眠いのに眠れない…',\n",
       "  '今日のアボカドはあじひとで食べるかな!誰か釣れるかな!',\n",
       "  '自己否定感が強い人は他人も否定する｡批判の多いのは、自分に自信がないと宣伝しているようなものだ｡自己肯定の人は、周りがなにを言っても気にならない｡それはそれと受け止めるのだ｡',\n",
       "  '今日カラーをしてもらったら鬼太郎ぽくなった｡仕事帰りに会った数名の知人にはいいやん!と言ってもらえて少し安心した｡でもね､ほんまはちょっとちゃうかな?って思ってるねん｡ま、来週まで楽しむか｡',\n",
       "  '鬼太郎ぽい体型の女子って…',\n",
       "  'うどんとラーメンハシゴしておなかパンパン!初､丸亀製麺からの彦ェ門!あっさりとんこつで完食!その筋では有名店らしい',\n",
       "  'なすの田楽食べたいな?',\n",
       "  'ご飯食べにいきたい…でも、もう眠いよパトラッシュ…',\n",
       "  '腰が痛い日々を送っています。色んなことが段々面倒になってきた｡昨日の晩から数えて初めての食事｡エビマヨ!アボカド!サーモン!鶏トマト煮!ふじいちでカロリーを取り戻す!',\n",
       "  '天王寺ぶらり｡あわよくば映画みてやろ?!程よくおなかも空いてきたし、一人でもいけそーないい感じの店あったら教えて?!',\n",
       "  'こんな時間に鴨つけうどん!ゆずピール入ってて結構おいしい!やるななか卯｡',\n",
       "  '経済ジャーナリスト金子さん(ほんまでっか出演)の訃報にびっくり｡病気みたい｡ご冥福をお祈りいたします｡',\n",
       "  '何でもないようなことが幸せだったと思う?何でもない夜のこと、腰痛で寝れないよーる?',\n",
       "  '少し前から毎日のようにつきまとわれている｡姿が見えない日もあって油断してるときっちり現れて､最近では睡眠妨害までしてくる…もういい加減にしてほしい!!!',\n",
       "  '腰痛の話｡寝てもさめても腰痛い｡痛みよ､去れ!イたとん!!',\n",
       "  'メルヘンに憧れがち｡現実を生きなければな。てか早く寝たい(>_<)!',\n",
       "  '今週も終わった!そして今から休みだ!明日は祝日か?何しよどこいこ!',\n",
       "  '寒いなぁ?鍋いこかな?',\n",
       "  'おなかすいた…orz',\n",
       "  '高校生みてると、笑顔可愛いな?とかなんかニヤけてしまう｡失われた青春を取り戻すようにかぶりつく私｡祝日の風景。',\n",
       "  'ハンバーグ食べたい!同志求ム!',\n",
       "  '本が好きだ｡いや､立ち読み､流し読み､本に囲まれているのが好きだ｡standardbookstoreが近所にあったら､住むかもしれない｡',\n",
       "  'ノーベル賞山中さんに興味津々｡朝からいろんな番組を見ているけど、まず目につくのはユーモアたっぷりでにこやかに話す奥さん｡会見ではまじめな印象が強かったけど、きっとご本人もユーモア溢れる方なのだろう。二人がどんな風に愛を育んできたのかが気になる。',\n",
       "  '恥ずかしくない仕事をしよう。心からそう思います。',\n",
       "  '西田辺は雷雨!!',\n",
       "  '調子よくしゃべった翌日はたいてい凹む。そろそろキャラ統一すべきかなぁ。',\n",
       "  'この性格の悪さを何とかしたい…',\n",
       "  'ほぼ毎日、パックのジュースをコンビニで買います。今日、袋の中にはジュースと割り箸が入ってました。眠かったんかな。',\n",
       "  'お客さんが切れない。ありがたいけどお腹すいた…ラスト一人がんばる!!',\n",
       "  '世の迷える女子に告ぐ。ニーハイの威力は、想像以上だ。',\n",
       "  '結局、わがままなんだな。己の幼さが歯がゆい。',\n",
       "  '観たい映画。新しい靴を買わなくちゃ、終の信託。メモ…',\n",
       "  '食材はその日食べる分しか買わないので、休日は出かけるまでほとんど食べられないことになる。でもこの胃と腸がが空になってく感じが好きだったりする。体が少し浄化されたような？アブナイ人ではないですよ。多分',\n",
       "  '同年代の女子が何を考え、どのように暮らしているか気になる。同い年と聞けばなおさら。最近気になる人。峰なゆかという女（ひと）…',\n",
       "  'たまたまイラストを目にすることが何度かあり、面白いな～と思っていたら最近インタビュー記事を読み、別口で気になってた著作の作者でありイラストの主だと発覚しびっくり。同い年と知りまた興味津々。とそこへきて知人の、Rtで峰さんのアカウントを知る。これは運命なのだと勝手に思っています。',\n",
       "  '田中里奈、たなかりな、ティーナカリーナ…',\n",
       "  'キョンキョンのアレ見逃すとこだった！あっぶね！ワンセグよありがとう！',\n",
       "  'さ、さむい…',\n",
       "  '今日は頑張った…ただいま我が家。散らかってるのももはや愛おしい。…でも片づけよ。',\n",
       "  '何気なく入ったDVDコーナーで流れていたONE PIECEに目を奪われる。これちょうどあかんとこやん！医者を！医者を教えでぐたざいﾞ!!',\n",
       "  '何だかサイコパスって言葉を最近よく目にする。流行ってるのかね？｢悪の教典 ｣面白そう。',\n",
       "  'やな季節が来たなぁ…',\n",
       "  '雨ニモ負ケズ みたいな人になりたいなぁ。',\n",
       "  '憤る。憤る28さい。出家でもしなければこんな感情からは解放されないと思う。',\n",
       "  '旅に出たい…',\n",
       "  '今朝起きていきなり柿をガブリとやって、切れた口の端が痛い。ついでに唇全体的に腫れてる。カブレたか…柿が好きすぎる。',\n",
       "  '職場でお寿司連れてってもらってお腹パンパン！デザートまで出してもらって大満足。苦しくなるほど食べられるなんて幸せじゃないか。',\n",
       "  '住む家がある、職がある、ちゃんと靴を履いて、毎日食べられる。離れていても家族や友達がいる。なんだ、必要なものは十分にあるじゃないか。',\n",
       "  '世の迷える男子に告ぐ。寝不足かつ空腹の女子に近づくとロクなことがないぞ！てことでたらふく食べたしふやけたし寝ます。おやすみなさい。',\n",
       "  'ホームパーティー楽しすぎてお泊まりした帰り道。祭りのあとはいつも寂しい',\n",
       "  '天気いいなーって歩いてたらスニーカーやさんからバービーボーイズ。シュール。',\n",
       "  '噂の壇蜜さんのブログが何となく面白い。',\n",
       "  'めっちゃ丁度いい光が部屋の窓から差し込む。こうして絵でも描いて暮らしたい。',\n",
       "  '今最も胸をはだけさせられベッドやソファに寝転がらされる男、生田斗真。すごいよ生田斗真。てれび戦士だったのに…',\n",
       "  '精神年齢が日に日に下がる気がする28さい。体年齢は日に日に上がる28さい。寝よ…',\n",
       "  '2012年下半期は様々なお一人様に挑戦しています。串カツは楽勝!!おやすみなさい',\n",
       "  '悲しくても辛くても、日々を生きなきゃいけなくて、そうしてうやむやにしながら生きていくんだなぁ。',\n",
       "  '休み前の晩にパジャマにメガネでてんこ盛りのご飯やいろんなおやつを食べながらテレビ見たりネットしたり、そうして時間に関わらず眠くなったらそのまま寝るのが最高に幸せ',\n",
       "  'こうやってデブになっていくのかなぁ。',\n",
       "  '普段から地味なのだが、休日の私はほんとに地味である。更に今日は輪をかけて、もう誰かを不快にしてしまうんじゃないかって程の地味さ。知り合いに会ったら怪しまれはしても気付かれないだろうな。',\n",
       "  '友達がハワイで挙式して、森で撮った写真がすごく素敵で羨ましかった。長い髪はゆる巻きダウンにして、お花の冠とベールをつけてるかんじ。木漏れ日を見上げる姿が可愛かったなぁ。',\n",
       "  '今日また、ふらりと入れる店が増えた。お酒もご飯も美味しかったし、何より、何となく温かい店だった。',\n",
       "  '昨日は誰にも会うまいと思ってたのに、帰り道にうっかり馴染みの店に行ってしまった。顔見知りがそばで飲んでいたが、案の定私には気づいていなかった。気配を消すのが得意になったもんだ',\n",
       "  'ハモネプ好き。',\n",
       "  'To be continuedの人、最近キモい人の役多いな…',\n",
       "  'アットホームダッドやってる！めっちゃ見たいけど寝る。連休なんて…',\n",
       "  '寒いってことに支配されて建設的な思考が奪われるから、冬は嫌い。'],\n",
       " 'input_ids': [tensor([    1, 29871, 34072, 30807, 32105, 32132, 32075, 32447]),\n",
       "  tensor([    1, 29871, 32442, 30199, 30534, 30723, 40629, 30466]),\n",
       "  tensor([    1, 29871, 32256, 33026, 32003, 34922, 30458, 37923]),\n",
       "  tensor([    1, 29871, 34481, 30298, 30330, 40749, 32004, 30267]),\n",
       "  tensor([    1, 29871, 32285, 33645, 29973, 29871, 32096, 30374]),\n",
       "  tensor([    1, 29871, 35006, 32885, 30458, 38944, 36537, 30538]),\n",
       "  tensor([    1, 29871, 41963,   242,   192,   164, 34106, 31206]),\n",
       "  tensor([    1, 29871, 30697, 32550, 30427, 32056, 30098, 31390]),\n",
       "  tensor([    1, 29871, 32216, 33026, 30366, 30267, 34369, 32850]),\n",
       "  tensor([    1, 29871, 32576, 32357, 30353, 32132, 32056, 30199]),\n",
       "  tensor([    1, 29871, 30534, 33449, 39316, 33003,   242,   192]),\n",
       "  tensor([    1,  4810, 29956,  3217, 29956, 31958, 30373, 31240]),\n",
       "  tensor([    1, 29871, 35151, 32174, 32035, 30098]),\n",
       "  tensor([    1,   350,  6259, 29933, 19453, 30199, 30313, 40866]),\n",
       "  tensor([    1, 29871, 38398, 30353, 30688, 36588, 37437, 30267]),\n",
       "  tensor([    1, 29871, 33243, 30098, 30419, 32249, 30409]),\n",
       "  tensor([    1, 29871, 31066, 31908, 31763, 42966, 30458, 36404]),\n",
       "  tensor([    1, 29871, 33202, 30313, 30449, 30805, 32004, 30199]),\n",
       "  tensor([    1, 29871, 33358, 31592, 30396, 35622, 30366, 33970]),\n",
       "  tensor([    1, 29871, 32893, 33678, 30353, 32021, 32075, 32086]),\n",
       "  tensor([    1, 29871, 30742, 35618, 33298, 30396, 33001, 34922]),\n",
       "  tensor([    1, 29871, 31163, 30449, 32719, 34476, 30364, 36757]),\n",
       "  tensor([    1, 29871, 30408, 30533, 30592, 40793, 32618, 30371]),\n",
       "  tensor([    1, 29871, 30413, 33466, 30371, 31390, 31090, 30458]),\n",
       "  tensor([    1, 29871, 36323, 32546, 30366, 32033, 30449, 31086]),\n",
       "  tensor([    1, 29871, 33298, 36634, 30330, 32119, 33192, 34201]),\n",
       "  tensor([    1, 29871, 30936, 30199, 36224, 30199, 29896, 29929]),\n",
       "  tensor([    1, 29871, 40179, 30298, 29991, 29906, 29955, 29900]),\n",
       "  tensor([    1, 29871, 35667, 30199, 33702, 30330, 31592, 36356]),\n",
       "  tensor([    1, 29871, 38086, 32009, 30538, 32082, 30499, 42447]),\n",
       "  tensor([    1, 29871, 33942, 30396, 30260, 31028, 32132, 30298]),\n",
       "  tensor([    1, 29871, 32380, 30968, 30098, 31250, 30326, 30787]),\n",
       "  tensor([    1, 29871, 34136, 32484, 30353, 30723, 32380, 30968]),\n",
       "  tensor([    1, 29871, 34481, 30298, 30199, 30353, 40749, 32004]),\n",
       "  tensor([    1, 29871, 32442, 30199, 41348, 30439, 30335, 30449]),\n",
       "  tensor([    1, 29871, 33315, 36102, 32024, 30458, 32888, 30313]),\n",
       "  tensor([    1, 29871, 32442, 32807, 30396, 32132, 33442, 32075]),\n",
       "  tensor([    1, 29871, 31820, 35679, 36172, 30298, 39613, 30199]),\n",
       "  tensor([    1, 29871, 30465, 31250, 33533, 34403, 30758, 30373]),\n",
       "  tensor([    1, 29871, 30371, 30427, 30199, 30395, 31739, 32194]),\n",
       "  tensor([    1, 29871, 34842, 32194, 30353, 32174, 32035, 30098]),\n",
       "  tensor([    1, 29871, 33942, 30458, 36487, 33359, 30396, 31545]),\n",
       "  tensor([    1, 29871, 30408, 30462, 30951, 42126, 30453,   242]),\n",
       "  tensor([    1, 29871, 32447, 32070, 30353, 41553, 32698, 36553]),\n",
       "  tensor([    1, 29871, 33090, 41970, 33634, 30659, 30319, 32017]),\n",
       "  tensor([    1, 29871, 31502, 39682, 32004, 32012, 30371, 32002]),\n",
       "  tensor([    1, 29871, 32238, 30658, 32005, 32713, 30199, 32012]),\n",
       "  tensor([    1, 29871, 36513, 30199, 31812,   242,   192,   164]),\n",
       "  tensor([    1, 29871, 35725, 32421, 30203, 30353, 36791, 33954]),\n",
       "  tensor([    1, 29871, 35380, 30723, 33880, 30366, 29991, 32160]),\n",
       "  tensor([    1, 29871, 36167, 33405, 29973, 35618, 30298, 30589]),\n",
       "  tensor([    1, 29871, 30697, 32550, 30427, 32056, 30098,   272]),\n",
       "  tensor([    1, 29871, 32889, 35098, 32192, 30364, 30330, 34256]),\n",
       "  tensor([    1, 29871, 39801, 32194, 32035, 29991, 30980, 31096]),\n",
       "  tensor([    1, 29871, 30346, 30458, 32302, 30955,   242,   192]),\n",
       "  tensor([    1, 29871, 35892, 32538, 33153, 30329, 30275, 32017]),\n",
       "  tensor([    1, 29871, 38395, 32093, 32004, 32169, 30396, 32704]),\n",
       "  tensor([    1, 29871, 30602, 30395, 34749, 30449, 39616, 33243]),\n",
       "  tensor([    1, 29871, 36381, 32216, 39169, 40083, 35833, 30449]),\n",
       "  tensor([    1, 29871, 32018, 34644, 30199, 32281, 30566, 30396]),\n",
       "  tensor([    1, 29871, 33522, 32713, 30330, 34791, 30199, 37661]),\n",
       "  tensor([    1, 29871, 30697, 31915, 32017, 30458, 34871, 32004]),\n",
       "  tensor([    1, 29871, 30793, 30199, 33264, 32044, 33704, 30353]),\n",
       "  tensor([    1, 29871, 34136, 30330, 37554, 32446, 32126, 30955]),\n",
       "  tensor([    1, 29871, 32241, 32035, 32484, 30267, 32610, 34463]),\n",
       "  tensor([    1, 29871, 34456, 30449, 32016, 30325, 33487, 30748]),\n",
       "  tensor([    1, 29871, 30980, 37937, 30199, 33704, 30458, 31502]),\n",
       "  tensor([    1, 29871, 30366, 32065, 30441, 34665, 30396, 30895]),\n",
       "  tensor([    1, 29871, 36092, 30755, 31696, 30330, 30366, 30371]),\n",
       "  tensor([    1, 29871, 30454, 32068, 30454, 32068, 30199, 34482]),\n",
       "  tensor([    1, 29871, 30566, 30330, 30566, 31834, 30298, 30098]),\n",
       "  tensor([    1, 29871, 32442, 30449, 34121, 30366, 30098, 32285]),\n",
       "  tensor([    1, 29871, 31502, 31648, 32037, 32414, 30366, 29928]),\n",
       "  tensor([    1, 29871, 31502, 30955, 30412, 32260, 30459, 33913]),\n",
       "  tensor([    1, 29871, 31111, 30371, 33649, 30458, 30805, 30366]),\n",
       "  tensor([    1, 29871, 33243, 30635, 30761, 32547, 30978, 30719]),\n",
       "  tensor([    1, 29871, 42862, 30332, 30267, 42862, 30332, 29906]),\n",
       "  tensor([    1, 29871, 32439, 30353, 30544, 32035, 30098]),\n",
       "  tensor([    1, 29871, 39908, 33412, 30466, 35991, 40310, 30396]),\n",
       "  tensor([    1, 29871, 34117, 30499, 30697, 37134, 34630, 30466]),\n",
       "  tensor([    1, 29871, 36434, 30613, 30458, 32008, 30330, 32427]),\n",
       "  tensor([    1, 29871, 30793, 30199, 33264, 32044, 35767, 30353]),\n",
       "  tensor([    1, 29871, 32572, 35822, 32155, 32473, 30466, 30697]),\n",
       "  tensor([    1, 29871, 35015, 32086, 35686, 32096, 34865, 30466]),\n",
       "  tensor([    1, 29871, 35940, 30199, 42388, 42468, 32017, 30199]),\n",
       "  tensor([    1, 29871, 36826, 40828, 32086, 30867, 30458, 32821]),\n",
       "  tensor([    1, 29871, 31482, 33229, 34586, 30396, 30449, 32053]),\n",
       "  tensor([    1, 29871, 33842, 33478, 30458, 30325, 30353, 30325]),\n",
       "  tensor([    1, 29871, 29906, 29900, 29896, 29906, 30470, 30557]),\n",
       "  tensor([    1, 29871, 34273, 32093, 32232, 42047, 32232, 30330]),\n",
       "  tensor([    1, 29871, 34430, 30658, 30199, 36656, 30353, 30715]),\n",
       "  tensor([    1, 29871, 32462, 31111, 32096, 30597, 30582, 30353]),\n",
       "  tensor([    1, 29871, 33361, 32005, 39415, 30371, 30199, 30955]),\n",
       "  tensor([    1, 29871, 33562, 30458, 36268, 30499, 42296, 32132]),\n",
       "  tensor([    1, 29871, 32442, 32065, 30330, 31706, 30513, 30453]),\n",
       "  tensor([    1, 29871, 33894, 30449, 32530, 30353, 30723, 30437]),\n",
       "  tensor([    1, 29871, 30758, 30761, 31038, 30605, 32302, 30267]),\n",
       "  tensor([    1,  1763,   367,  7572, 30199, 30313, 30330, 32576]),\n",
       "  tensor([    1, 29871, 39960, 32572, 30617, 32314, 31111, 32096]),\n",
       "  tensor([    1, 29871, 36167, 32096, 32002, 30353, 37369, 30566])],\n",
       " 'query': ['<s> ぼけっとしてたらこんな',\n",
       "  '<s> 今日の月も白くて',\n",
       "  '<s> 早寝するつもりが飲み物',\n",
       "  '<s> 眠い、眠れない。',\n",
       "  '<s> ただいま? って新',\n",
       "  '<s> 表情筋が衰えてき',\n",
       "  '<s> やばい｡おもろ',\n",
       "  '<s> おなかすいた…夜',\n",
       "  '<s> よく寝た。暴走',\n",
       "  '<s> 最近アップにしていたの',\n",
       "  '<s> 月末ミーティング終了��',\n",
       "  '<s> COWCOWヨシ君',\n",
       "  '<s> シャンプーいきたい…',\n",
       "  '<s> BIGBANGの人がえ',\n",
       "  '<s> 久々に自炊した。',\n",
       "  '<s> 雨…（笑）',\n",
       "  '<s> 外反母趾が悪化',\n",
       "  '<s> 待ち人は来ないの',\n",
       "  '<s> 昔夢を語った仲間',\n",
       "  '<s> みんな幸せになったらいい',\n",
       "  '<s> 回鍋肉を作るつもり',\n",
       "  '<s> 朝はパンケーキとサンド',\n",
       "  '<s> 天地明察みたいな',\n",
       "  '<s> 不確かな夜風が',\n",
       "  '<s> 投げかけたものは返',\n",
       "  '<s> 肉まん、サーモンロール',\n",
       "  '<s> 次の月曜の19',\n",
       "  '<s> ヤバい!270',\n",
       "  '<s> 最強の二人、夢売る',\n",
       "  '<s> ごくありきたりで俗',\n",
       "  '<s> 腰をイワしてい',\n",
       "  '<s> 落語…どしよ',\n",
       "  '<s> 結局映画にも落語',\n",
       "  '<s> 眠いのに眠れない',\n",
       "  '<s> 今日のアボカドは',\n",
       "  '<s> 自己否定感が強い人',\n",
       "  '<s> 今日カラーをしてもらったら',\n",
       "  '<s> 鬼太郎ぽい体型の',\n",
       "  '<s> うどんとラーメンハシ',\n",
       "  '<s> なすの田楽食べ',\n",
       "  '<s> ご飯食べにいきたい…',\n",
       "  '<s> 腰が痛い日々を送',\n",
       "  '<s> 天王寺ぶらり�',\n",
       "  '<s> こんな時間に鴨つけうどん',\n",
       "  '<s> 経済ジャーナリスト金子さん',\n",
       "  '<s> 何でもないようなこと',\n",
       "  '<s> 少し前から毎日のよう',\n",
       "  '<s> 腰痛の話｡',\n",
       "  '<s> メルヘンに憧れがち',\n",
       "  '<s> 今週も終わった!そして',\n",
       "  '<s> 寒いなぁ?鍋いこ',\n",
       "  '<s> おなかすいた…or',\n",
       "  '<s> 高校生みてると、笑顔',\n",
       "  '<s> ハンバーグ食べたい!同志',\n",
       "  '<s> 本が好きだ��',\n",
       "  '<s> ノーベル賞山中さん',\n",
       "  '<s> 恥ずかしくない仕事をしよう',\n",
       "  '<s> 西田辺は雷雨',\n",
       "  '<s> 調子よくしゃべった翌日は',\n",
       "  '<s> この性格の悪さを',\n",
       "  '<s> ほぼ毎日、パックのジュース',\n",
       "  '<s> お客さんが切れない',\n",
       "  '<s> 世の迷える女子に',\n",
       "  '<s> 結局、わがままなんだ',\n",
       "  '<s> 観たい映画。新しい靴',\n",
       "  '<s> 食材はその日食べる分',\n",
       "  '<s> 同年代の女子が何',\n",
       "  '<s> たまたまイラストを目',\n",
       "  '<s> 田中里奈、たな',\n",
       "  '<s> キョンキョンのアレ',\n",
       "  '<s> さ、さむい…',\n",
       "  '<s> 今日は頑張った…ただ',\n",
       "  '<s> 何気なく入ったD',\n",
       "  '<s> 何だかサイコパス',\n",
       "  '<s> やな季節が来た',\n",
       "  '<s> 雨ニモ負ケズ',\n",
       "  '<s> 憤る。憤る2',\n",
       "  '<s> 旅に出たい…',\n",
       "  '<s> 今朝起きていきなり柿を',\n",
       "  '<s> 職場でお寿司連れて',\n",
       "  '<s> 住む家がある、職',\n",
       "  '<s> 世の迷える男子に',\n",
       "  '<s> ホームパーティー楽しすぎてお',\n",
       "  '<s> 天気いいなーって歩いて',\n",
       "  '<s> 噂の壇蜜さんの',\n",
       "  '<s> めっちゃ丁度いい光が部屋',\n",
       "  '<s> 今最も胸をはだけ',\n",
       "  '<s> 精神年齢が日に日',\n",
       "  '<s> 2012年下',\n",
       "  '<s> 悲しくても辛くても、',\n",
       "  '<s> 休み前の晩にパ',\n",
       "  '<s> こうやってデブに',\n",
       "  '<s> 普段から地味なのだ',\n",
       "  '<s> 友達がハワイで挙式して',\n",
       "  '<s> 今日また、ふらり',\n",
       "  '<s> 昨日は誰にも会',\n",
       "  '<s> ハモネプ好き。',\n",
       "  '<s> To be continuedの人、最近',\n",
       "  '<s> アットホームダッドやって',\n",
       "  '<s> 寒いってことに支配さ']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "\treturn dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/trl/lib/python3.10/site-packages/transformers/modeling_utils.py:4225: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "The cos_cached attribute will be removed in 4.39. Bear in mind that its contents changed in v4.38. Use the forward method of RoPE from now on instead. It is not used in the `LlamaAttention` class\n",
      "The sin_cached attribute will be removed in 4.39. Bear in mind that its contents changed in v4.38. Use the forward method of RoPE from now on instead. It is not used in the `LlamaAttention` class\n",
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'TheBloke/Swallow-13B-GPTQ', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'TheBloke/Swallow-13B-GPTQ', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AutoModelForCausalLMWithValueHead' object has no attribute 'quantize_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLMWithValueHead\u001b[38;5;241m.\u001b[39mfrom_pretrained(config\u001b[38;5;241m.\u001b[39mmodel_name, low_cpu_mem_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m ref_model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLMWithValueHead\u001b[38;5;241m.\u001b[39mfrom_pretrained(config\u001b[38;5;241m.\u001b[39mmodel_name, low_cpu_mem_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mexllama_set_max_input_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_input_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2304\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m ref_model \u001b[38;5;241m=\u001b[39m exllama_set_max_input_length(ref_model, max_input_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2304\u001b[39m)\n\u001b[1;32m      8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(config\u001b[38;5;241m.\u001b[39mmodel_name)\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/auto_gptq/utils/exllama_utils.py:19\u001b[0m, in \u001b[0;36mexllama_set_max_input_length\u001b[0;34m(model, max_input_length)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# The import is set here to avoid a global import. Arguably this is quite ugly, it would be better to have lazy loading.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllama_kernels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cleanup_buffers_cuda, prepare_buffers\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_config\u001b[49m\u001b[38;5;241m.\u001b[39mdesc_act:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe method exllama_set_max_input_length should be called only when using the exllama backend **with act-order**.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     24\u001b[0m uses_exllama \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoModelForCausalLMWithValueHead' object has no attribute 'quantize_config'"
     ]
    }
   ],
   "source": [
    "# Load LLM models\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name, low_cpu_mem_usage=True, device_map=\"auto\")\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name, low_cpu_mem_usage=True, device_map=\"auto\")\n",
    "\n",
    "model = exllama_set_max_input_length(model, max_input_length=2304)\n",
    "ref_model = exllama_set_max_input_length(ref_model, max_input_length=2304)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n",
      "2\n",
      "</s>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token)\n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.eos_token)\n",
    "print(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize PPOTrainer\n",
    "ppo_trainer = PPOTrainer(config, model, ref_model, tokenizer, dataset=dataset, data_collator=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ppo_trainer.accelerator.device\n",
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "\tdevice = 0 if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_pipe = pipeline(\"text-classification\", model=\"/workspace/trl_example/emo_model/bert-large-japanese-v2/checkpoint-4276/\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/trl/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'JOY', 'score': -3.8448824882507324},\n",
       "  {'label': 'SADNESS', 'score': 1.988978385925293},\n",
       "  {'label': 'ANTICIPATION', 'score': -2.9459354877471924},\n",
       "  {'label': 'SURPRISE', 'score': -3.4601120948791504},\n",
       "  {'label': 'RAGE', 'score': -5.411185264587402},\n",
       "  {'label': 'FEAR', 'score': -3.390770435333252},\n",
       "  {'label': 'DISGUST', 'score': -3.706437826156616},\n",
       "  {'label': 'TRUST', 'score': -5.7069501876831055}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"今日は残念ながら大雨で体育祭は中止です。\"\n",
    "emotion_pipe(text, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.pad_token_id}\n",
    "# gen_kwargs = {\"min_length\": 0, \"top_k\": 50, \"top_p\": 0.95, \"do_sample\": True, \"pad_token_id\": tokenizer.pad_token_id}\n",
    "gen_kwargs = {\"min_length\": 0, \"top_k\": 500, \"top_p\": 0.95, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select emotion\n",
    "emotion = \"JOY\"\n",
    "\n",
    "emotion_dict = {\"JOY\": 0,\n",
    "    \"SADNESS\": 1,\n",
    "    \"ANTICIPATION\": 2,\n",
    "    \"SURPRISE\": 3,\n",
    "    \"RAGE\": 4,\n",
    "    \"FEAR\": 5,\n",
    "    \"DISGUST\": 6,\n",
    "    \"TRUST\": 7\n",
    "\t}\n",
    "\n",
    "emotion_id = emotion_dict[emotion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [01:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=2304:\nfrom auto_gptq import exllama_set_max_input_length\nmodel = exllama_set_max_input_length(model, max_input_length=2304)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m rewards \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(output[emotion_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m pipe_outputs]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#### Run PPO step\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mppo_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:721\u001b[0m, in \u001b[0;36mPPOTrainer.step\u001b[0;34m(self, queries, responses, scores, response_masks)\u001b[0m\n\u001b[1;32m    718\u001b[0m full_kl_penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mkl_penalty \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 721\u001b[0m     all_logprobs, logits_or_none, values, masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatched_forward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_kl_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptional_peft_ctx():\n\u001b[1;32m    730\u001b[0m         ref_logprobs, ref_logits_or_none, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatched_forward_pass(\n\u001b[1;32m    731\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_peft_model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_model,\n\u001b[1;32m    732\u001b[0m             queries,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    735\u001b[0m             return_logits\u001b[38;5;241m=\u001b[39mfull_kl_penalty,\n\u001b[1;32m    736\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:994\u001b[0m, in \u001b[0;36mPPOTrainer.batched_forward_pass\u001b[0;34m(self, model, queries, responses, model_inputs, return_logits, response_masks)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response_masks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     response_masks_batch \u001b[38;5;241m=\u001b[39m response_masks[i \u001b[38;5;241m*\u001b[39m fbs : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m fbs]\n\u001b[0;32m--> 994\u001b[0m logits, _, values \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n\u001b[1;32m    997\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m input_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/trl/models/modeling_value_head.py:171\u001b[0m, in \u001b[0;36mAutoModelForCausalLMWithValueHead.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_peft_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_model\u001b[38;5;241m.\u001b[39mactive_peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPREFIX_TUNING\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 171\u001b[0m base_model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m base_model_output\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    178\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m base_model_output\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1196\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1196\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1016\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1006\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1007\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         cache_position,\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:754\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    753\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 754\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    757\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:240\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py:185\u001b[0m, in \u001b[0;36mQuantLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    179\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe exllama kernel for GPTQ requires a float16 input activation, while \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was passed. Casting to float16.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure you loaded your model with torch_dtype=torch.float16, that the model definition does not inadvertently cast to float32, or disable AMP Autocast that may produce float32 intermediate activations in the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    183\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mhalf()\n\u001b[0;32m--> 185\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mext_q4_matmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     out\u001b[38;5;241m.\u001b[39madd_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/conda/envs/trl/lib/python3.10/site-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py:42\u001b[0m, in \u001b[0;36mext_q4_matmul\u001b[0;34m(x, q4, q4_width)\u001b[0m\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     40\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], q4_width), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mq4_matmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mview(outshape)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The temp_state buffer is too small in the exllama backend for GPTQ with act-order. Please call the exllama_set_max_input_length function to increase the buffer size for a sequence length >=2304:\nfrom auto_gptq import exllama_set_max_input_length\nmodel = exllama_set_max_input_length(model, max_input_length=2304)"
     ]
    }
   ],
   "source": [
    "# output_min_length = 10\n",
    "# output_max_length = 10\n",
    "# output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    # \"min_length\": 0,\n",
    "    \"top_k\": 500,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "    # \"pad_token_id\": tokenizer.pad_token_id,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"temperature\": 1\n",
    "}\n",
    "\n",
    "\n",
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    #### Get response from calm\n",
    "    response_tensors = []\n",
    "    for query in query_tensors:\n",
    "        # gen_len = output_length_sampler()\n",
    "        gen_len = 10\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "        if len(response.squeeze()) < gen_len:\n",
    "            gen_len = len(response.squeeze())\n",
    "        response_tensors.append(response.squeeze()[-gen_len:])\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "\n",
    "    #### Compute sentiment score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs = emotion_pipe(texts, **sent_kwargs)\n",
    "    rewards = [torch.tensor(output[emotion_id][\"score\"]) for output in pipe_outputs]\n",
    "\n",
    "    #### Run PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    # ppo_trainer.log_stats(stats, batch, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/trl/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/trl/lib/python3.10/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response (before)</th>\n",
       "      <th>response (after)</th>\n",
       "      <th>rewards (before)</th>\n",
       "      <th>rewards (after)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>眠い( ́д⊂</td>\n",
       "      <td>)\\n今日こそお題通り、2時間</td>\n",
       "      <td>)\\n「そんな顔してたの!?」ってびっくり</td>\n",
       "      <td>-2.820653</td>\n",
       "      <td>0.963286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>なんやかんやで観光地なんよね</td>\n",
       "      <td>ー。\\n南越前町も、福井県大</td>\n",
       "      <td>」\\n「えっ? えっ?」\\n「</td>\n",
       "      <td>-0.597175</td>\n",
       "      <td>1.345917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>結構大きな地震来ましたね。最近また</td>\n",
       "      <td>大きな地震多いなぁ。今日はちょっと肌寒いかなぁ</td>\n",
       "      <td>地震が多くなってきた気がします。\\nさて、そんな</td>\n",
       "      <td>-2.396218</td>\n",
       "      <td>-2.329535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pさん、一からソロチャンネルってのはやっぱり</td>\n",
       "      <td>気心知れた人じゃないと難しいですからね。そういう</td>\n",
       "      <td>すごいよなー。\\nえ? えっ?</td>\n",
       "      <td>-2.840656</td>\n",
       "      <td>1.780662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>大吉先生かわいい</td>\n",
       "      <td>っす。\\nさて、お次はT-ARA</td>\n",
       "      <td>!\\nえー、もう10年以上も前</td>\n",
       "      <td>-3.223706</td>\n",
       "      <td>-0.879288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>将棋の渡辺くん見てると、渡辺先生</td>\n",
       "      <td>ってほんとすごいよなぁと思う。\\nあの年</td>\n",
       "      <td>「え!?お、また髪の毛切ったの!?</td>\n",
       "      <td>1.693428</td>\n",
       "      <td>1.775075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>中学校の同級生が、お茶の品評会で</td>\n",
       "      <td>、県知事賞という最優秀な賞をとったという</td>\n",
       "      <td>金賞を受賞したという話をしていました。\\nそのお茶は</td>\n",
       "      <td>-1.279851</td>\n",
       "      <td>0.183977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>稲葉先生も見えてる・・・</td>\n",
       "      <td>\\n2月10日~11日に毎年恒例の新</td>\n",
       "      <td>」「えっ!? えっ!? どういうこと!?」\\n</td>\n",
       "      <td>-1.227304</td>\n",
       "      <td>1.544269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>どんなにお金なくてもクヌルプに行きたいと</td>\n",
       "      <td>(もうすでに)思っていたから、そういう気持ちが少しでも</td>\n",
       "      <td>何度聞いたことか(笑)\\n\\nそして、</td>\n",
       "      <td>-1.823187</td>\n",
       "      <td>-0.600454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>どーせ教育とか言って正当化するの</td>\n",
       "      <td>やめてほしいわな\\nお前みたいな雑魚には</td>\n",
       "      <td>」\\n「え、え? どうしてそんな</td>\n",
       "      <td>-3.721265</td>\n",
       "      <td>-1.485774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>最近、メガネなしだと、テレビの番組</td>\n",
       "      <td>が全然見えなくなるので、つい最近まで、</td>\n",
       "      <td>が全然分かりませんでした。\\n初めて知ったのは、</td>\n",
       "      <td>-0.019317</td>\n",
       "      <td>0.805217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>素直な正直者が叩かれて、ずる</td>\n",
       "      <td>ずる行くのも仕方ないな、と思ったりします。</td>\n",
       "      <td>いよなあと思ってしまう(笑)。\\n「</td>\n",
       "      <td>-3.241756</td>\n",
       "      <td>-1.485538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>空港に着いてしまった。</td>\n",
       "      <td>\\n今回は、1泊2日で福岡へ遊び</td>\n",
       "      <td>この旅でも、何度も飛行機に乗っている。初めて</td>\n",
       "      <td>-4.051402</td>\n",
       "      <td>-0.857707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>窓開けてる 風が気持ちいい</td>\n",
       "      <td>です。\\nKid's CUPで遊ぶ</td>\n",
       "      <td>!」\\n「あ! なにこれ??」</td>\n",
       "      <td>-3.653402</td>\n",
       "      <td>-1.718957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>私の人生を変えてくれた人に感謝</td>\n",
       "      <td>と愛をこめて\\nプレゼントでいただいた紅茶。</td>\n",
       "      <td>します」\\n「えーっ!? なんか</td>\n",
       "      <td>-2.594278</td>\n",
       "      <td>-1.240885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>進撃のねずみのイエダニ作戦に</td>\n",
       "      <td>怯えながら、何とか潜入を成功させて、次々</td>\n",
       "      <td>気づいたという人がいて、それがびっくりニュースだったらしい</td>\n",
       "      <td>-3.331265</td>\n",
       "      <td>1.734140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>迫りくるお腹のぐるぐるに対抗して</td>\n",
       "      <td>、さらに力を出し合い、最後まで戦い抜くことができました</td>\n",
       "      <td>、思わず笑った。あの3人(笑</td>\n",
       "      <td>-2.919137</td>\n",
       "      <td>-1.370244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>今週のMotoGPも面白かったです。</td>\n",
       "      <td>\\n【レース結果:MotoGP最終戦バレンシア】</td>\n",
       "      <td>\\n2日目のライダースクラブレースは、大</td>\n",
       "      <td>-3.039917</td>\n",
       "      <td>-2.712636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>歳とったら縁側のある、風がよく</td>\n",
       "      <td>流れる家で暮らしたいと思っていました。\\nそんな思いから</td>\n",
       "      <td>通る家があるらしいね。\\nええ!そんな</td>\n",
       "      <td>-5.527319</td>\n",
       "      <td>1.678151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>いつからモニターと電源に接続が必要と</td>\n",
       "      <td>の話です。 モニター側はACアダプターを接続するだけで</td>\n",
       "      <td>出て、いろいろ説明を受けましたが、何の問題もなかった</td>\n",
       "      <td>-5.434226</td>\n",
       "      <td>-1.012406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>のりさーん!恋を知らない君へ</td>\n",
       "      <td>/ 中島みゆき』など、数々のヒット曲や</td>\n",
       "      <td>!」\\n「え?なに?ええ?......</td>\n",
       "      <td>-1.229177</td>\n",
       "      <td>0.080082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>おはよーーー!!!今日は2つ企画</td>\n",
       "      <td>やります!\\n1.手相観:1</td>\n",
       "      <td>あるの!!\\nえ?もう2つある</td>\n",
       "      <td>-5.527787</td>\n",
       "      <td>1.303665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>『リッチマン、プアウーマン』</td>\n",
       "      <td>で共演していた夏野剛(コラムニスト)</td>\n",
       "      <td>でも、そのギャップが絶賛されていました。\\nまた</td>\n",
       "      <td>-0.505997</td>\n",
       "      <td>-0.902571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>結婚式の頃、お互い社会人になったばかりでほんと</td>\n",
       "      <td>何してたんだろう...という感じに当時を振り返ってお話</td>\n",
       "      <td>初めてのお付き合いだったんだけど、まさか3年も付き</td>\n",
       "      <td>-0.866358</td>\n",
       "      <td>1.090926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>神様が粋な計らいをしてきた、</td>\n",
       "      <td>な計らいをしてきた、と思うしかないんですよね。&lt;|endoftext|&gt;</td>\n",
       "      <td>という風に考えていかざるを得ないですね。\\nこの</td>\n",
       "      <td>-1.653069</td>\n",
       "      <td>-1.903039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>父子が義両親とお墓参りに行った</td>\n",
       "      <td>とき、亡くなった義両親にお供えされたものの中に</td>\n",
       "      <td>時、\\nあそこにあったのは2人のお</td>\n",
       "      <td>-1.545406</td>\n",
       "      <td>0.102033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>コンビニで不定期発売される新作のハッピータ</td>\n",
       "      <td>ーンを買ってきたので食べてみた。\\n『劇場版</td>\n",
       "      <td>ーンが、今朝のTVに流れていました。\\n</td>\n",
       "      <td>-3.065185</td>\n",
       "      <td>0.691038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>小枝のチョコミント味</td>\n",
       "      <td>チョコレートとミントアイスとチョコレートが口の中で</td>\n",
       "      <td>あの!有名なやつですか?\\nあれ、まだ</td>\n",
       "      <td>-0.926987</td>\n",
       "      <td>1.402480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>時間が足りないって言いながらもちゃんとtwitterは</td>\n",
       "      <td>やってましたね。\\n— アリツ・サ</td>\n",
       "      <td>更新してるんですね(笑)\\n【3月</td>\n",
       "      <td>-0.675775</td>\n",
       "      <td>0.466151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>佐倉綾音に真剣なオタクに振りかけた</td>\n",
       "      <td>言葉「そういうキャラじゃないんだよね」\\n『ラブライブ</td>\n",
       "      <td>、あの「彼女」の話です。\\n「</td>\n",
       "      <td>-1.247451</td>\n",
       "      <td>0.595370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>乾杯覚えてからひたすら乾杯</td>\n",
       "      <td>しまくった。\\n二日目は、2月</td>\n",
       "      <td>してたんです」\\n「え? そんなことある</td>\n",
       "      <td>-2.793592</td>\n",
       "      <td>1.518015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>今年度履修した科目来年上限突破できない</td>\n",
       "      <td>と、来年履修できなくなる。来年上限突破しないと</td>\n",
       "      <td>」などの話も聞かれていました。\\n3</td>\n",
       "      <td>-4.591299</td>\n",
       "      <td>-1.583101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          query                     response (before)  \\\n",
       "0                       眠い( ́д⊂                       )\\n今日こそお題通り、2時間   \n",
       "1                なんやかんやで観光地なんよね                        ー。\\n南越前町も、福井県大   \n",
       "2             結構大きな地震来ましたね。最近また               大きな地震多いなぁ。今日はちょっと肌寒いかなぁ   \n",
       "3        Pさん、一からソロチャンネルってのはやっぱり              気心知れた人じゃないと難しいですからね。そういう   \n",
       "4                      大吉先生かわいい                      っす。\\nさて、お次はT-ARA   \n",
       "5              将棋の渡辺くん見てると、渡辺先生                  ってほんとすごいよなぁと思う。\\nあの年   \n",
       "6              中学校の同級生が、お茶の品評会で                  、県知事賞という最優秀な賞をとったという   \n",
       "7                  稲葉先生も見えてる・・・                    \\n2月10日~11日に毎年恒例の新   \n",
       "8          どんなにお金なくてもクヌルプに行きたいと           (もうすでに)思っていたから、そういう気持ちが少しでも   \n",
       "9              どーせ教育とか言って正当化するの                  やめてほしいわな\\nお前みたいな雑魚には   \n",
       "10            最近、メガネなしだと、テレビの番組                   が全然見えなくなるので、つい最近まで、   \n",
       "11               素直な正直者が叩かれて、ずる                 ずる行くのも仕方ないな、と思ったりします。   \n",
       "12                  空港に着いてしまった。                      \\n今回は、1泊2日で福岡へ遊び   \n",
       "13                窓開けてる 風が気持ちいい                     です。\\nKid's CUPで遊ぶ   \n",
       "14              私の人生を変えてくれた人に感謝                と愛をこめて\\nプレゼントでいただいた紅茶。   \n",
       "15               進撃のねずみのイエダニ作戦に                  怯えながら、何とか潜入を成功させて、次々   \n",
       "16             迫りくるお腹のぐるぐるに対抗して           、さらに力を出し合い、最後まで戦い抜くことができました   \n",
       "17           今週のMotoGPも面白かったです。              \\n【レース結果:MotoGP最終戦バレンシア】   \n",
       "18              歳とったら縁側のある、風がよく          流れる家で暮らしたいと思っていました。\\nそんな思いから   \n",
       "19           いつからモニターと電源に接続が必要と           の話です。 モニター側はACアダプターを接続するだけで   \n",
       "20               のりさーん!恋を知らない君へ                   / 中島みゆき』など、数々のヒット曲や   \n",
       "21             おはよーーー!!!今日は2つ企画                        やります!\\n1.手相観:1   \n",
       "22               『リッチマン、プアウーマン』                    で共演していた夏野剛(コラムニスト)   \n",
       "23      結婚式の頃、お互い社会人になったばかりでほんと           何してたんだろう...という感じに当時を振り返ってお話   \n",
       "24               神様が粋な計らいをしてきた、  な計らいをしてきた、と思うしかないんですよね。<|endoftext|>   \n",
       "25              父子が義両親とお墓参りに行った               とき、亡くなった義両親にお供えされたものの中に   \n",
       "26        コンビニで不定期発売される新作のハッピータ                ーンを買ってきたので食べてみた。\\n『劇場版   \n",
       "27                  小枝のチョコミント味              チョコレートとミントアイスとチョコレートが口の中で   \n",
       "28  時間が足りないって言いながらもちゃんとtwitterは                     やってましたね。\\n— アリツ・サ   \n",
       "29            佐倉綾音に真剣なオタクに振りかけた           言葉「そういうキャラじゃないんだよね」\\n『ラブライブ   \n",
       "30                乾杯覚えてからひたすら乾杯                       しまくった。\\n二日目は、2月   \n",
       "31          今年度履修した科目来年上限突破できない               と、来年履修できなくなる。来年上限突破しないと   \n",
       "\n",
       "                 response (after)  rewards (before)  rewards (after)  \n",
       "0           )\\n「そんな顔してたの!?」ってびっくり         -2.820653         0.963286  \n",
       "1                 」\\n「えっ? えっ?」\\n「         -0.597175         1.345917  \n",
       "2        地震が多くなってきた気がします。\\nさて、そんな         -2.396218        -2.329535  \n",
       "3                 すごいよなー。\\nえ? えっ?         -2.840656         1.780662  \n",
       "4                 !\\nえー、もう10年以上も前         -3.223706        -0.879288  \n",
       "5               「え!?お、また髪の毛切ったの!?          1.693428         1.775075  \n",
       "6      金賞を受賞したという話をしていました。\\nそのお茶は         -1.279851         0.183977  \n",
       "7         」「えっ!? えっ!? どういうこと!?」\\n         -1.227304         1.544269  \n",
       "8             何度聞いたことか(笑)\\n\\nそして、         -1.823187        -0.600454  \n",
       "9                」\\n「え、え? どうしてそんな         -3.721265        -1.485774  \n",
       "10       が全然分かりませんでした。\\n初めて知ったのは、         -0.019317         0.805217  \n",
       "11             いよなあと思ってしまう(笑)。\\n「         -3.241756        -1.485538  \n",
       "12         この旅でも、何度も飛行機に乗っている。初めて         -4.051402        -0.857707  \n",
       "13                !」\\n「あ! なにこれ??」         -3.653402        -1.718957  \n",
       "14               します」\\n「えーっ!? なんか         -2.594278        -1.240885  \n",
       "15  気づいたという人がいて、それがびっくりニュースだったらしい         -3.331265         1.734140  \n",
       "16                 、思わず笑った。あの3人(笑         -2.919137        -1.370244  \n",
       "17           \\n2日目のライダースクラブレースは、大         -3.039917        -2.712636  \n",
       "18            通る家があるらしいね。\\nええ!そんな         -5.527319         1.678151  \n",
       "19     出て、いろいろ説明を受けましたが、何の問題もなかった         -5.434226        -1.012406  \n",
       "20            !」\\n「え?なに?ええ?......         -1.229177         0.080082  \n",
       "21                あるの!!\\nえ?もう2つある         -5.527787         1.303665  \n",
       "22       でも、そのギャップが絶賛されていました。\\nまた         -0.505997        -0.902571  \n",
       "23      初めてのお付き合いだったんだけど、まさか3年も付き         -0.866358         1.090926  \n",
       "24       という風に考えていかざるを得ないですね。\\nこの         -1.653069        -1.903039  \n",
       "25              時、\\nあそこにあったのは2人のお         -1.545406         0.102033  \n",
       "26           ーンが、今朝のTVに流れていました。\\n         -3.065185         0.691038  \n",
       "27            あの!有名なやつですか?\\nあれ、まだ         -0.926987         1.402480  \n",
       "28              更新してるんですね(笑)\\n【3月         -0.675775         0.466151  \n",
       "29                、あの「彼女」の話です。\\n「         -1.247451         0.595370  \n",
       "30           してたんです」\\n「え? そんなことある         -2.793592         1.518015  \n",
       "31             」などの話も聞かれていました。\\n3         -4.591299        -1.583101  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### get a batch from the dataset\n",
    "bs = 32\n",
    "game_data = dict()\n",
    "dataset.set_format(\"pandas\")\n",
    "df_batch = dataset[:].sample(bs)\n",
    "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "query_tensors = df_batch[\"input_ids\"].tolist()\n",
    "\n",
    "response_tensors_ref, response_tensors = [], []\n",
    "\n",
    "#### get response from gpt2 and gpt2_ref\n",
    "for i in range(bs):\n",
    "    # gen_len = output_length_sampler()\n",
    "    gen_len = 10\n",
    "    output = ref_model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors_ref.append(output)\n",
    "    output = model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors.append(output)\n",
    "\n",
    "#### decode responses\n",
    "game_data[\"response (before)\"] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
    "game_data[\"response (after)\"] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
    "\n",
    "#### sentiment analysis of query/response pairs before/after\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n",
    "game_data[\"rewards (before)\"] = [output[emotion_id][\"score\"] for output in emotion_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n",
    "game_data[\"rewards (after)\"] = [output[emotion_id][\"score\"] for output in emotion_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(game_data)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rewards (before)   -2.396147\n",
       "rewards (after)    -0.031927\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "median:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rewards (before)   -2.693935\n",
       "rewards (after)     0.143005\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"mean:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].mean())\n",
    "print()\n",
    "print(\"median:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/workspace/trl_example/save_dir/open-calm-1b-SURPRISE/tokenizer_config.json',\n",
       " '/workspace/trl_example/save_dir/open-calm-1b-SURPRISE/special_tokens_map.json',\n",
       " '/workspace/trl_example/save_dir/open-calm-1b-SURPRISE/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(f\"/workspace/trl_example/save_dir/{config.model_name.split('/')[-1]}-{emotion}\", push_to_hub=False)\n",
    "tokenizer.save_pretrained(f\"/workspace/trl_example/save_dir/{config.model_name.split('/')[-1]}-{emotion}\", push_to_hub=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
